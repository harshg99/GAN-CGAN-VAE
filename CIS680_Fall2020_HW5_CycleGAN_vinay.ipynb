{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CIS680_Fall2020_HW5_CycleGAN_vinay.ipynb","provenance":[{"file_id":"1lcATcEszEAonshYaly-JauxfnVXh7Lmt","timestamp":1638222200492}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"E4v6rxBKYp7Z"},"source":["# Download the dataset and supporting codes and pre-trained models"]},{"cell_type":"markdown","metadata":{"id":"kIMdTpeGg-Vw"},"source":["https://drive.google.com/file/d/1D3m6I2S8xIvdOHBkvwSSFof5OTJZCDSt/view?usp=drivesdk\n","\n","https://drive.google.com/file/d/1CDRMyBA3Hk_gmbk1xkAm7aRHXBOQQigu/view?usp=drivesdk\n","\n","https://drive.google.com/file/d/1so6AQ0_Pg255COjAzEOOVPlDzTJFVQro/view?usp=drivesdk"]},{"cell_type":"code","metadata":{"id":"2CQQXc9JUUYU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638243720446,"user_tz":300,"elapsed":342,"user":{"displayName":"Vinay Senthil","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmsQ9aJp6SeA8H090djjSp7DBkhc2iypynvWf64g=s64","userId":"04588656014823898940"}},"outputId":"7e6d6491-93aa-480e-a968-fc2ea80cd60c"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"id":"CW3wE6aNYekA","colab":{"base_uri":"https://localhost:8080/","height":537},"executionInfo":{"status":"error","timestamp":1638223206414,"user_tz":300,"elapsed":2488,"user":{"displayName":"Vinay Senthil","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmsQ9aJp6SeA8H090djjSp7DBkhc2iypynvWf64g=s64","userId":"04588656014823898940"}},"outputId":"a1ddc9c5-fed0-4293-d118-a3352feb46f7"},"source":["from google.colab import auth\n","auth.authenticate_user()\n","from googleapiclient.discovery import build\n","drive_service = build('drive', 'v3')\n","import io\n","import os\n","from googleapiclient.http import MediaIoBaseDownload\n","def download_file(fn, file_id):\n","    request = drive_service.files().get_media(fileId=file_id)\n","    downloaded = io.BytesIO()\n","    downloader = MediaIoBaseDownload(downloaded, request)\n","    done = False\n","    while done is False:\n","        # _ is a placeholder for a progress object that we ignore.\n","        # (Our file is small, so we skip reporting progress.)\n","        _, done = downloader.next_chunk()\n","    downloaded.seek(0)\n","    folder = fn.split('/')\n","    if len(folder) > 1:\n","        os.makedirs(folder[0], exist_ok=True)\n","    with open(fn, 'wb') as f:\n","        f.write(downloaded.read())\n","id_to_fn = {\n","# '1D3rH-gSxIECZnoyc5k77PEucKBVzoiBc': 'edges2shoes.zip',\n","# '1D3m6I2S8xIvdOHBkvwSSFof5OTJZCDSt': 'edges2shoes.zip',\n","'1CDRMyBA3Hk_gmbk1xkAm7aRHXBOQQigu': 'CycleGAN_support.zip',\n","# '1so6AQ0_Pg255COjAzEOOVPlDzTJFVQro': 'test_case.zip',\n","# '1l7gHikhCz64hYHL4n_Ps7nufQcddcRyR': 'test_case.zip'\n","\n","}\n","# download all files into the vm\n","for fid, fn in id_to_fn.items():\n","    print(\"Downloading %s from %s\" % (fn, fid))\n","    download_file(fn, fid)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    624\u001b[0m         \"\"\"\n\u001b[0;32m--> 625\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-da578800833d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthenticate_user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogleapiclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscovery\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdrive_service\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'drive'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'v3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/auth.py\u001b[0m in \u001b[0;36mauthenticate_user\u001b[0;34m(clear_output)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0mcontext_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtemporary\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mclear_output\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_noop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0m_gcloud_login\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0m_install_adc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0mcolab_tpu_addr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'COLAB_TPU_ADDR'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/auth.py\u001b[0m in \u001b[0;36m_gcloud_login\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;31m# https://github.com/jupyter/notebook/issues/3159\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m     \u001b[0mgcloud_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"oIZPNwOJZUB7"},"source":["! unzip -q edges2shoes.zip\n","! unzip -q CycleGAN_support.zip\n","! unzip -q test_case.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xjqctk8cdlw-","executionInfo":{"status":"ok","timestamp":1638243837854,"user_tz":300,"elapsed":370,"user":{"displayName":"Vinay Senthil","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmsQ9aJp6SeA8H090djjSp7DBkhc2iypynvWf64g=s64","userId":"04588656014823898940"}},"outputId":"c1719658-345c-482c-ad42-9eb54364f07b"},"source":["cd /content/drive/MyDrive/CIS680HW/HW5"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1jXHfcccydID9lvS-kWbUti7okmyAiPhc/HW5\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AB22UfGxhJlD","executionInfo":{"status":"ok","timestamp":1638237278703,"user_tz":300,"elapsed":254,"user":{"displayName":"Vinay Senthil","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmsQ9aJp6SeA8H090djjSp7DBkhc2iypynvWf64g=s64","userId":"04588656014823898940"}},"outputId":"a5248d0d-331a-4509-fab1-9f469159b90d"},"source":["ls"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" CIS680_Fall2020_HW5_CycleGAN_template.ipynb\n"," CIS680_Fall2020_HW5_CycleGAN_vinay.ipynb\n"," CIS680_Fall2020_HW5_VAE_GAN_template.ipynb\n","'HW 5 Report.gdoc'\n"," \u001b[0m\u001b[01;34mimages\u001b[0m/\n"," inception_score.py\n"," \u001b[01;34mstl10_data\u001b[0m/\n"," \u001b[01;34mtest_case_CycleGAN\u001b[0m/\n"," \u001b[01;34mtest_case_GAN\u001b[0m/\n"," Zee_CIS680_Fall2020_HW5_VAE_GAN_template.ipynb\n"]}]},{"cell_type":"code","metadata":{"id":"YlXxvkeeenrJ"},"source":["! unzip -q edges2shoes.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5deohquc7YGs","executionInfo":{"status":"ok","timestamp":1638243607720,"user_tz":300,"elapsed":183,"user":{"displayName":"Vinay Senthil","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmsQ9aJp6SeA8H090djjSp7DBkhc2iypynvWf64g=s64","userId":"04588656014823898940"}},"outputId":"a1a062b3-b668-4e24-dfcb-2ab488763394"},"source":["!pwd"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n","pwd: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S56PLa_I7Lra","executionInfo":{"status":"ok","timestamp":1638243593984,"user_tz":300,"elapsed":437,"user":{"displayName":"Vinay Senthil","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmsQ9aJp6SeA8H090djjSp7DBkhc2iypynvWf64g=s64","userId":"04588656014823898940"}},"outputId":"4222c3c9-8ebb-4b96-fe7d-d77a49de8105"},"source":["! unzip -q cyclegan_files.zip"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n","unzip:  cannot find or open cyclegan_files.zip, cyclegan_files.zip.zip or cyclegan_files.zip.ZIP.\n"]}]},{"cell_type":"markdown","metadata":{"id":"rT6-1Ax8YyQr"},"source":["# CycleGAN training (TODO)"]},{"cell_type":"code","metadata":{"id":"3zQDWN_lMWJI","colab":{"base_uri":"https://localhost:8080/","height":860},"executionInfo":{"status":"error","timestamp":1638245228926,"user_tz":300,"elapsed":268,"user":{"displayName":"Vinay Senthil","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmsQ9aJp6SeA8H090djjSp7DBkhc2iypynvWf64g=s64","userId":"04588656014823898940"}},"outputId":"48f0b159-5f23-487b-c9d0-1cd75e455b78"},"source":["import torch\n","import pdb\n","\n","D_A = torch.load('D_A.pt')\n","D_B = torch.load('test_case_CycleGAN/D_B.pt')\n","G_BA = torch.load('test_case_CycleGAN/G_BA.pt')\n","G_AB = torch.load('test_case_CycleGAN/G_AB.pt')\n","valid = torch.load('test_case_CycleGAN/valid.pt')\n","fake = torch.load('test_case_CycleGAN/fake.pt')\n","fake_A = torch.load('test_case_CycleGAN/fake_A.pt')\n","fake_B = torch.load('test_case_CycleGAN/fake_B.pt')\n","real_A = torch.load('test_case_CycleGAN/real_A.pt')\n","real_B = torch.load('test_case_CycleGAN/real_B.pt')\n","criterion_GAN = torch.load('test_case_CycleGAN/criterion_GAN.pt')\n","criterion_cycle = torch.load('test_case_CycleGAN/criterion_cycle.pt')\n","\n","\n","\n","def loss_discriminator(fakefG, D, real2D, valid, fake, criterion_GAN):\n","    '''\n","    loss_discriminator function is applied to compute loss for discriminator D_A and D_B,\n","    For example, we want to compute loss for D_A. The loss is consisted of two parts: \n","    D(real_A) and D(G(real_B)). We want to penalize the distance between D(real_A) part and 1 and \n","    distance between D(G(real_B)) part and 0. \n","    We will want to first compute discriminator loss given real_A and valid, which is all 1.\n","    Then we want to forward real_A through G_AB network to get fake image batch \n","    and compute discriminator loss given fake batch and fake, which is all 0.\n","    Finally, add up these two loss as the total discriminator loss.\n","    '''\n","    real_loss = criterion_GAN(D(real2D), valid)\n","    fake_pred = criterion_GAN(fakefG.detach(), fake)\n","    loss_D = real_loss + fake_loss\n","\n","    return loss_D\n","\n","\n","\n","def loss_generator(G, real2G, D, valid, criterion_GAN):\n","    '''\n","    loss_generator function is applied to compute loss for both generator G_AB and G_BA:\n","    For example, we want to compute the loss for G_AB.\n","    real2G will be the real image in domain A, then we map real2G into domain B to get fake B,\n","    then we compute the loss between D_B(fake_B) and valid, which is all 1.\n","    The fake_B image will also be one of the outputs, since we want to use it in the loss_cycle_consis.\n","    '''\n","\n","    fake_o_G = G(real2G)\n","    loss_G = criterion_GAN(D(fake_o_G), valid)\n","        \n","    return loss_G, fake_o_G\n","\n","\n","\n","def loss_cycle_consis(G, fakefG, real, criterion_cycle):\n","    '''\n","    loss_cycle_consis function is applied to both cycle consistency loss:\n","    between recovered A and original A,\n","    between recovered B and original B.\n","    For example, we want to compute the cycle consistency loss between recovered A and original A.\n","    fake2G will be the generated image in domain B, then we map fake2G back into domain A to get recovered A,\n","    then we compute the loss between recovered A and original A\n","    '''\n","    \n","    recoveredA = G(fakefG)\n","    loss_cycle = criterion_cycle(recoveredA, real)\n","    \n","    return loss_cycle\n","\n","\n","# test case\n","\n","# test_loss_GAN_AB = torch.load('test_case_CycleGAN/loss_GAN_AB.pt')\n","# test_loss_cycle_A = torch.load('test_case_CycleGAN/loss_cycle_A.pt')\n","# test_loss_D_A = torch.load('test_case/loss_D_A.pt')\n","# loss_GAN_AB, fake_B = loss_generator(G_AB, real_A, D_B, valid, criterion_GAN)\n","# loss_cycle_A = loss_cycle_consis(G_BA, fake_B, real_A, criterion_cycle)\n","# loss_D_A = loss_discriminator(fake_A, D_A, real_A, valid, fake, criterion_GAN)\n","\n","\n","# print('test case loss_D_A:', test_loss_D_A.item())\n","# print('computed loss_D_A:', loss_D_A.item())\n","\n","# print('test case test_loss_GAN_AB:', test_loss_GAN_AB.item())\n","# print('computed test_loss_GAN_AB:', loss_GAN_AB.item())\n","\n","# print('test case loss_cycle_A:', test_loss_cycle_A.item())\n","# print('computed loss_cycle_A:', loss_cycle_A.item())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n"]},{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-4-1af6aa69aefb>\", line 4, in <module>\n","    D_A = torch.load('D_A.pt')\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 594, in load\n","    with _open_file_like(f, 'rb') as opened_file:\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 230, in _open_file_like\n","    return _open_file(name_or_buffer, mode)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 211, in __init__\n","    super(_open_file, self).__init__(open(name, mode))\n","FileNotFoundError: [Errno 2] No such file or directory: 'D_A.pt'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'FileNotFoundError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n","    return f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","  File \"/usr/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n","    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n","  File \"/usr/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n","    filename = getsourcefile(frame) or getfile(frame)\n","  File \"/usr/lib/python3.7/inspect.py\", line 696, in getsourcefile\n","    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n","  File \"/usr/lib/python3.7/inspect.py\", line 725, in getmodule\n","    file = getabsfile(object, _filename)\n","  File \"/usr/lib/python3.7/inspect.py\", line 709, in getabsfile\n","    return os.path.normcase(os.path.abspath(_filename))\n","  File \"/usr/lib/python3.7/posixpath.py\", line 383, in abspath\n","    cwd = os.getcwd()\n","FileNotFoundError: [Errno 2] No such file or directory\n"]},{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"]}]},{"cell_type":"code","metadata":{"id":"sM1-EnX11hXX"},"source":["import warnings\n","warnings.filterwarnings(\"ignore\")\n","from torch.autograd import Variable\n","from torch.utils import data\n","from torch.utils.data import DataLoader, TensorDataset\n","from torch import nn, optim\n","from datasets import *\n","from models import *\n","import argparse, os\n","import itertools\n","import torch\n","import time\n","import pdb\n","import matplotlib.pyplot as plt\n","\n","\n","# Training Configurations\n","# (You may put your needed configuration here. Please feel free to add more or use argparse. )\n","train_img_dir = './edges2shoes/train/'\n","img_shape = (3, 128, 128)\n","n_residual_blocks = 6\n","num_epochs = 2\n","batch_size = 1\n","lr_rate = 0.0002      # Adam optimizer learning rate\n","betas = (0.5, 0.999)  # Adam optimizer beta 1, beta 2\n","lambda_cyc = 10.0 \t  # cycle loss weight\n","latent_dim = 8        # latent dimension for the encoded images from domain B\n","report_feq = 10        # Visualize image every 'report_feq' iters\n","visual_feq = 1000\n","save_feq = 1000      # Save models every 'save_feq' iters\n","\n","# Random seeds (optional)\n","torch.manual_seed(1); np.random.seed(1)\n","\n","# set device\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Normalize image tensor\n","def norm(image):\n","    return (image/255.0-0.5)*2.0\n","\n","# Denormalize image tensor\n","def denorm(tensor):\n","    return ((tensor+1.0)/2.0)*255.0\n","\n","train_dataset = Edge2Shoe(train_img_dir)\n","train_loader = data.DataLoader(train_dataset, batch_size=batch_size)\n","print('the length of training data:', len(train_dataset))\n","# Losses\n","criterion_GAN = torch.nn.MSELoss()\n","criterion_cycle = torch.nn.L1Loss()\n","\n","cuda = torch.cuda.is_available()\n","\n","input_shape = img_shape\n","\n","# Initialize generator and discriminator\n","G_AB = GeneratorResNet(input_shape, n_residual_blocks)\n","G_BA = GeneratorResNet(input_shape, n_residual_blocks)\n","D_A = Discriminator(input_shape)\n","D_B = Discriminator(input_shape)\n","\n","\n","if cuda:\n","    G_AB = G_AB.to(device)\n","    G_BA = G_BA.to(device)\n","    D_A = D_A.to(device)\n","    D_B = D_B.to(device)\n","    criterion_GAN.to(device)\n","    criterion_cycle.to(device)\n","\n","# Initialize weights\n","G_AB.apply(weights_init_normal)\n","G_BA.apply(weights_init_normal)\n","D_A.apply(weights_init_normal)\n","D_B.apply(weights_init_normal)\n","\n","\n","\n","# Define optimizer\n","optimizer_G = torch.optim.Adam(itertools.chain(G_AB.parameters(), G_BA.parameters()), lr=lr_rate, betas=betas)\n","optimizer_D_A = torch.optim.Adam(D_A.parameters(), lr=lr_rate, betas=betas)\n","optimizer_D_B = torch.optim.Adam(D_B.parameters(), lr=lr_rate, betas=betas)\n","\n","# For adversarial loss\n","Tensor = torch.cuda.FloatTensor if cuda else torch.Tensor\n","\n","# loss recorder\n","running_loss_D_A = 0\n","running_loss_D_B = 0\n","running_loss_GAN_AB = 0\n","running_loss_GAN_BA = 0\n","running_loss_cycle = 0\n","running_total_loss = 0\n","\n","loss_D_A = []\n","loss_D_B = []\n","loss_GAN_AB = []\n","loss_GAN_BA = []\n","loss_cycle = []\n","total_loss = []\n","# Training\n","total_steps = len(train_loader)*num_epochs; step = 0\n","for e in range(num_epochs):\n","    start = time.time()\n","    for idx, data in enumerate(train_loader):\n","        ########## Process Inputs ##########\n","        edge_tensor, rgb_tensor = data\n","        edge_tensor, rgb_tensor = norm(edge_tensor).to(device), norm(rgb_tensor).to(device)\n","        real_A = edge_tensor; real_B = rgb_tensor;\n","\n","        # Adversarial ground truths\n","        valid = Variable(Tensor(np.ones((real_A.size(0), *D_A.output_shape))), requires_grad=False)\n","        fake = Variable(Tensor(np.zeros((real_A.size(0), *D_A.output_shape))), requires_grad=False)\n","\n","        # ------------------\n","        #  Train Generators\n","        # ------------------\n","        G_AB.train(); G_BA.train()\n","        optimizer_G.zero_grad()\n","\n","        # Generator loss\n","        loss_GAN_AB, fake_B = loss_generator(G_AB, real_A, D_B, valid, criterion_GAN)\n","        loss_GAN_BA, fake_A = loss_generator(G_BA, real_B, D_A, valid, criterion_GAN)\n","        loss_GAN = (loss_GAN_AB + loss_GAN_BA) / 2\n","\n","        # Cycle loss\n","        loss_cycle_A = loss_cycle_consis(G_BA, fake_B, real_A, criterion_cycle)\n","        loss_cycle_B = loss_cycle_consis(G_AB, fake_A, real_B, criterion_cycle)\n","        loss_cycle = (loss_cycle_A + loss_cycle_B) / 2\n","\n","        # Total loss\n","        loss_G = loss_GAN + lambda_cyc * loss_cycle\n","\n","        loss_G.backward()\n","        optimizer_G.step()\n","\n","\n","        # -----------------------\n","        #  Train Discriminator A\n","        # -----------------------\n","\n","        optimizer_D_A.zero_grad()\n","\n","        # function to compute loss_D_A\n","        loss_D_A = loss_discriminator(fake_A, D_A, real_A, valid, fake, criterion_GAN)\n","        loss_D_A = loss_D_A / 2\n","        # update the D_A network\n","        loss_D_A.backward()\n","        optimizer_D_A.step()\n","\n","\n","        # -----------------------\n","        #  Train Discriminator B\n","        # -----------------------\n","        optimizer_D_B.zero_grad()\n","\n","        # function to compute loss_D_A\n","        loss_D_B = loss_discriminator(fake_B, D_B, real_B, valid, fake, criterion_GAN)\n","        loss_D_B = loss_D_B / 2\n","        # update the D_B network\n","        loss_D_B.backward()\n","        optimizer_D_B.step()\n","\n","\n","        \n","\n","\n","\n","        running_total_loss += (loss_GAN + lambda_cyc * loss_cycle + loss_D_A + loss_D_B).item()\n","\n","        running_loss_GAN_AB += loss_GAN_AB.item()\n","        running_loss_GAN_BA += loss_GAN_BA.item()\n","        running_loss_D_A += loss_D_A.item()\n","        running_loss_D_B += loss_D_B.item()\n","        running_loss_cycle += lambda_cyc * loss_cycle.item()\n","        ########## Visualization ##########\n","        if step % report_feq == report_feq-1:\n","            print('Train Epoch: {} {:.0f}% \\tTotal Loss: {:.6f} \\tLoss_G_AB: {:.6f}\\tLoss_G_BA: {:.6f}\\tLoss_cycle: {:.6f}\\tLoss_D_A: {:.6f}\\tLoss_D_B: {:.6f}'.format\n","                    (e+1, 100. * idx / len(train_loader), running_total_loss / report_feq, \n","                    running_loss_GAN_AB/report_feq, running_loss_GAN_BA/report_feq, \n","                    running_loss_cycle/report_feq, running_loss_D_A/report_feq, \n","                    running_loss_D_B/report_feq))\n","            running_loss_D_A = 0\n","            running_loss_D_B = 0\n","            running_loss_GAN_AB = 0\n","            running_loss_GAN_BA = 0\n","            running_loss_cycle = 0\n","            running_total_loss = 0\n","            end = time.time()\n","            print(e, step, 'T: ', end-start)\n","            start = end\n","        ########## Visualize Generated images ##########\n","        if step % visual_feq == 0:\n","            vis_fake_A = denorm(fake_A[0].detach()).cpu().data.numpy().astype(np.uint8)\n","            vis_fake_B = denorm(fake_B[0].detach()).cpu().data.numpy().astype(np.uint8)\n","            vis_real_B = denorm(real_B[0].detach()).cpu().data.numpy().astype(np.uint8)\n","            vis_real_A = denorm(real_A[0].detach()).cpu().data.numpy().astype(np.uint8)\n","            fig, axs = plt.subplots(2,2, figsize = (5,5))\t\n","            \n","            axs[0,0].imshow(vis_real_A.transpose(1,2,0))\n","            axs[0,0].set_title('real images')\n","            axs[0,1].imshow(vis_fake_B.transpose(1,2,0))\n","            axs[0,1].set_title('generated images')\n","            axs[1,0].imshow(vis_real_B.transpose(1,2,0))\n","            axs[1,1].imshow(vis_fake_A.transpose(1,2,0))\n","            plt.show()\n","        ########## Save Generators ##########\n","        if step % save_feq == save_feq-1:\n","            if not os.path.exists('models'): os.mkdir('models')\n","            torch.save(G_AB, '/content/models/G_AB.pt')\n","            torch.save(G_BA, '/content/models/G_BA.pt')\n","            # feel free to save checkpoint if you need retrain the model...\n","\n","        step += 1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yx1sPwiu_04L"},"source":["# CycleGAN testing (TODO)"]},{"cell_type":"code","metadata":{"id":"t_5OoGMfKFuU"},"source":["from torch.utils.data import DataLoader, TensorDataset\n","test_batch_size = 1\n","test_img_dir = './edges2shoes/val/'\n","test_dataset = Edge2Shoe(test_img_dir)\n","test_loader = DataLoader(test_dataset, batch_size=test_batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"naYmwWpq9Eg_"},"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","G_AB = torch.load('/content/models/G_AB.pt')\n","G_BA = torch.load('/content/models/G_BA.pt')\n","if cuda:\n","    G_AB = G_AB.to(device)\n","    G_BA = G_BA.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7m1b2H0pLOfu"},"source":["G_AB.eval()\n","G_BA.eval()\n","\n","################################\n","# Please visualize real_edge, fake_shoe, real_shoe, fake_edge in 2-by-2 grids:\n","\n","################################        \n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vnLrUjjVfxA-"},"source":["# Quantitative Evaluation"]},{"cell_type":"markdown","metadata":{"id":"c-T0HP1fBO1j"},"source":["## FID Score computation"]},{"cell_type":"markdown","metadata":{"id":"Wgxl2Y9gsJ8_"},"source":["First, we have to create 6 datasets:\n","- Domain A real set 1\n","- Domain A real set 2\n","- Domain A generate set\n","\n","- Domain B real set 1\n","- Domain B real set 2\n","- Domain B generate set\n","\n"]},{"cell_type":"markdown","metadata":{"id":"hBkdwX3sf2qb"},"source":["Create folder to save images and create dataset."]},{"cell_type":"code","metadata":{"id":"RKIC1KfjvUsH"},"source":["! mkdir real_A_1 real_A_2 gen_A\n","! mkdir real_B_1 real_B_2 gen_B"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oYMyd8CuBPJz"},"source":["# First create test data loader\n","from torch.utils.data import DataLoader, TensorDataset\n","from torchvision.utils import save_image\n","test_batch_size = 1\n","test_img_dir = './edges2shoes/val/'\n","test_dataset = Edge2Shoe(test_img_dir)\n","test_loader = DataLoader(test_dataset, batch_size=test_batch_size)\n","\n","# indicate the device we will use\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Load learnt Generator G_AB and G_BA\n","G_AB = torch.load('/content/models/G_AB.pt').to(device)\n","G_BA = torch.load('/content/models/G_BA.pt').to(device)\n","\n","# the size of dataset, we want to evaluate on\n","evaluate_num = 100\n","\n","# make the gen data set and folder\n","real_A_set_1 = []\n","real_A_set_2 = []\n","real_B_set_1 = []\n","real_B_set_2 = []\n","\n","gen_set_A = []\n","gen_set_B = []\n","\n","for idx, data in enumerate(test_loader, 0):\n","    real_A, real_B = data\n","    # plt.imshow(real_A.type(torch.uint8).squeeze(0).cpu().permute(1,2,0))\n","    # plt.show()\n","    real_A, real_B = norm(real_A).to(device), norm(real_B).to(device)\n","    # plt.imshow(denorm(real_A).type(torch.uint8).squeeze(0).cpu().permute(1,2,0))\n","    # plt.imshow(denorm(real_A).squeeze(0).cpu().permute(1,2,0))\n","    # plt.show()\n","    # print(real_A.shape)\n","    \n","    if idx < evaluate_num:\n","        fake_A = G_BA(real_B)\n","        fake_B = G_AB(real_A)\n","        real_A_set_1.append(denorm(real_A.detach()))\n","        real_B_set_1.append(denorm(real_B.detach()))\n","        gen_set_A.append(denorm(fake_A.detach()))\n","        gen_set_B.append(denorm(fake_B.detach()))\n","        \n","        # plt.imshow(data[0].type(torch.uint8).squeeze(0).permute(1,2,0))\n","        # plt.imshow(denorm(real_A).squeeze(0).cpu().permute(1,2,0))\n","        # plt.imshow(denorm(real_A).type(torch.uint8).squeeze(0).cpu().permute(1,2,0))\n","        # plt.show()\n","        plt.imsave('./real_A_1/real_A' + str(idx) + '.png', denorm(real_A).type(torch.uint8).cpu().squeeze().permute(1,2,0).numpy())\n","        plt.imsave('./real_B_1/real_B' + str(idx) + '.png', denorm(real_B).type(torch.uint8).cpu().squeeze().permute(1,2,0).numpy())\n","        plt.imsave('./gen_A/gen_A' + str(idx) + '.png', denorm(fake_A).type(torch.uint8).cpu().squeeze().permute(1,2,0).numpy())\n","        plt.imsave('./gen_B/gen_B' + str(idx) + '.png', denorm(fake_B).type(torch.uint8).cpu().squeeze().permute(1,2,0).numpy())\n","        # save_image(denorm(real_A).type(torch.uint8).squeeze(), './real_A_1/real_A' + str(idx) + '.png', normalize=False)\n","\n","        # save_image(denorm(real_B).detach().squeeze(), './real_B_1/real_B' + str(idx) + '.png', normalize=False)\n","        # save_image(denorm(fake_A).detach().squeeze(), './gen_A/gen_A' + str(idx) + '.png', normalize=False)\n","        # save_image(denorm(fake_B).detach().squeeze(), './gen_B/gen_B' + str(idx) + '.png', normalize=False)\n","        # del real_A; del real_B; del fake_A; del fake_B\n","\n","    elif evaluate_num <= idx < 2*evaluate_num:\n","        real_A_set_2.append(real_A.detach())\n","        real_B_set_2.append(real_B.detach())\n","        plt.imsave('./real_A_2/real_A' + str(idx) + '.png', denorm(real_A).type(torch.uint8).cpu().squeeze().permute(1,2,0).numpy())\n","        plt.imsave('./real_B_2/real_B' + str(idx) + '.png', denorm(real_B).type(torch.uint8).cpu().squeeze().permute(1,2,0).numpy())\n","        # save_image(denorm(real_A).detach().squeeze(), './real_A_2/real_A' + str(idx) + '.png', normalize=False)\n","        # save_image(denorm(real_B).detach().squeeze(), './real_B_2/real_B' + str(idx) + '.png', normalize=False)\n","    \n","    if idx == 2*evaluate_num-1:\n","        break\n","# make 6 pytorch dataset\n","real_A_dataset_1 = TensorDataset(torch.cat(real_A_set_1))\n","real_A_dataset_2 = TensorDataset(torch.cat(real_A_set_2))\n","real_B_dataset_1 = TensorDataset(torch.cat(real_B_set_1))\n","real_B_dataset_2 = TensorDataset(torch.cat(real_B_set_2))\n","gen_dataset_A = TensorDataset(torch.cat(gen_set_A))\n","gen_dataset_B = TensorDataset(torch.cat(gen_set_B))\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OVQjy_tuGPdm"},"source":["## Compute FID score"]},{"cell_type":"code","metadata":{"id":"7hJpNaRcGOQl"},"source":["! pip install pytorch-fid"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G2q_mIuDK8wP"},"source":["print('computing FID score between real_edge_1 and real_edge_2')\n","! python -m pytorch_fid '/content/real_A_1' '/content/real_A_2' --gpu 0\n","\n","print('computing FID score between real_edge_1 and gen_edge')\n","! python -m pytorch_fid '/content/real_A_1' '/content/gen_A' --gpu 0\n","\n","print('computing FID score between real_shoe_1 and real_shoe_2')\n","! python -m pytorch_fid '/content/real_B_1' '/content/real_B_2' --gpu 0\n","\n","print('computing FID score between real_shoe_1 and gen_shoe')\n","! python -m pytorch_fid '/content/real_B_1' '/content/gen_B' --gpu 0"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gNG7AkY_Gt61"},"source":["## Compute IS score"]},{"cell_type":"code","metadata":{"id":"qC7FTAYHFGV2"},"source":["from inception_score import inception_score\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","print('IS score for real_edge_1 data set:')\n","print(inception_score(real_A_dataset_1, cuda=True, batch_size=64, resize=True, splits=1))\n","print('IS score for gen_edge data set:')\n","print(inception_score(gen_dataset_A, cuda=True, batch_size=64, resize=True, splits=1))\n","\n","\n","print('IS score for real_shoe_1:')\n","print(inception_score(real_B_dataset_1, cuda=True, batch_size=64, resize=True, splits=1))\n","print('IS score for gen_shoe data set:')\n","print(inception_score(gen_dataset_B, cuda=True, batch_size=64, resize=True, splits=1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MJcwTlhcDvmE"},"source":[""],"execution_count":null,"outputs":[]}]}